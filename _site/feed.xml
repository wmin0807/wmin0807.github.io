<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>Stylish Jekyll Theme</description>
		<link>/</link>
		<atom:link href="/" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Hadoop的单机和集群部署</title>
				<description>&lt;h4 id=&quot;hadoop&quot;&gt;hadoop单机部署步骤：&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Required software&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Java(Java 7 以上）&lt;/li&gt;
  &lt;li&gt;SSH&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;download the latest version&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Local(Standalone) Mode&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;hadoop可以直接独自运行在一个JVM程序里面。无需运行任何守护进程，所有程序都在同一个JVM上。在独立模式下测试和调试MapReduce程序很方便，因此该模式在开发阶段比较合适。在独立模式（本地模式）下将使用本地文件系统和本地MapReduce作业运行器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pseudo-Distributed Mode&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以使用伪分布式的方式运行hadoop，也就是所有的守护进程都是运行在一台机器上。&lt;/p&gt;

&lt;p&gt;配置文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;etc/hadoop/core-site.xml:

&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;

etc/hadoop/hdfs-site.xml:

&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在需要使ssh localhost连接本地无需密码：&lt;/p&gt;

&lt;p&gt;ssh localhost&lt;/p&gt;

&lt;p&gt;如果执行这条命令需要密码，则需要执行如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa
  $ cat ~/.ssh/id_dsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下是一个例子，没有运行在yarn上。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先需要格式化文件系统：  bin/hdfs namenode -format&lt;/li&gt;
  &lt;li&gt;在后台启动一个namenode 和 datanode: sbin/start-dfs.sh，启动后可以在logs目录下查看日志，也可以访问： http://localhost:50070/&lt;/li&gt;
  &lt;li&gt;在hdfs中创建一个目录：bin/hdfs dfs -mkdir /user&lt;/li&gt;
  &lt;li&gt;拷贝本地文件到hdfs中：bin/hdfs dfs -put etc/hadoop/*.xml /user&lt;/li&gt;
  &lt;li&gt;执行程序：bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar grep /input /output ‘dfs[a-z.]+’&lt;/li&gt;
  &lt;li&gt;查看输出，可以先把hdfs中的文件拷贝到本地后查看：bin/hdfs dfs -get output output&lt;/li&gt;
  &lt;li&gt;cat output/*&lt;/li&gt;
  &lt;li&gt;或者直接在hdfs中查看： bin/hdfs dfs -cat output/*&lt;/li&gt;
  &lt;li&gt;停止hdfs可以使用： sbin/stop-dfs.sh&lt;/li&gt;
  &lt;li&gt;可以使用jps命令查看进程。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;使用： bin/hdfs dfs -rmdir /user/trssmas/output 删除指定的目录&lt;/li&gt;
  &lt;li&gt;使用： bin/hdfs dfs -rm /user/trssmas/output/file1 删除指定路径下的文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;在单个节点上运行YARN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先需要配置：etc/hadoop/mapred-site.xml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置： etc/hadoop/yarn-site.xml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个时候可以启动yarn了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sbin/start-yarn.sh
sbin/stop-yarn.sh
sbin/stop-all.sh 结束所有的进程
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;hadoop-1&quot;&gt;hadoop的集群部署步骤&lt;/h4&gt;

&lt;p&gt;在集群的部署和伪分布式的部署不太一样，具体操作如下：&lt;/p&gt;

&lt;p&gt;首先本地环境是两台物理机，ip地址分别为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;10.249.150.51 （master)&lt;/li&gt;
  &lt;li&gt;10.249.150.52  (slave)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;选取51作为master， 52作为slave&lt;/p&gt;

&lt;p&gt;hadoop的版本这次选取的是： hadoop-2.5.1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;准备工作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在安装之前需要分配一个hadoop用户专门用于hadoop的操作，同时在每台机器上安装JAVA(推荐使用oracle的JDK）和SSH。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;修改每台主机的用户名，51这台机器为master，所以修改这台机器的用户名为master。linux下修改主机的名字会随着使用的linux发行版不同而不同，但是如果只是暂时修改主机名（就是重启后用命令修改的主机名失效）可以在所有linux发行版中使用：hostname 修改的名字。但是推荐是永久修改主机名，这里举出Ubuntu和Centos两种发行版修改主机名的方式：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Ubuntu：直接编辑etc下的hostname文件： vi /etc/hostname 修改主机名。编辑完后需要重启才能生效。&lt;/li&gt;
      &lt;li&gt;Centos：直接编辑etc/sysconfig/network：将HOSTNAME修改为主机名，如果没有就添加一行： HOSTNAME=master。编辑完后需要重新启动才能生效。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改hosts文件，修改hosts文件后可以直接使用主机名代替ip地址访问其他机器。hosts文件的修改是通过编辑etc/hosts文件得到的，vi /etc/hosts文件。&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;  127.0.0.1 localhost
  10.249.150.51 master
  10.249.150.52 slave
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;通过修改hostname 和 hosts文件，这样我们可以通过访问主机名就能访问机器了，比如可以使用：&lt;/p&gt;

    &lt;p&gt;ping master 或者 ping slave 都能够ping通。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：修改hostname和修改hosts文件每台机器上都要做，修改hostname是为了将每天机器的主机名改成该机器相应的名字，比如将52改成slave。修改hosts文件，每天机器都需要做相同的操作，比如：在51上要做： 10.249.150.51 master &amp;amp;&amp;amp; 10.249.150.52 slave，那在52上也要做相同的操作，这样才能在每台机器上ping通所有机器。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置master使用SSH无密码登录所有slave。这个操作要让master能够使用ssh无密码的访问所有slave。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;首先在master主机上，使用 ssh-keygen -t rsa 命令生成密钥对。&lt;/li&gt;
      &lt;li&gt;然后使用 cat ~/.ssh/id_rsa.pub » ~/.ssh/authorized_keys命令，配置ssh访问本地无需要密码。&lt;/li&gt;
      &lt;li&gt;完成后可以使用： ssh master检查一下是否需要密码才能登录，如果无需密码说明ssh设置正确，否则需要重新设置一次。&lt;/li&gt;
      &lt;li&gt;在完成了master的设置之后，需要把master上产生的公钥发送到每个slave机器上，命令如下： scp ~/.ssh/id_rsa.pub 用户名@slave的IP地址:~/.ssh/ 这条命令的意思是：使用scp命令将将id_rsa.pub拷贝到slave地址的~/.ssh目录下。&lt;/li&gt;
      &lt;li&gt;在slave机器下执行：cat ~/.id_rsa.pub » ~/.ssh/authorized_keys&lt;/li&gt;
      &lt;li&gt;在所有的slave节点操作完成后，可以在master节点上使用ssh slave来验证是否需要密码才能登录。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;设置hadoop的配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;需要在etc/hadoop文件中修改slaves文件，将文件中的内容全部换成所有slave的名字，注意，如果原文件中又localhost，就将localhost删掉，同时每行写一个slave机器的名字，如下所示：&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; slave1
 slave2
 ....
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改core-site.xml文件，在core-site.xml文件中配置成如下：&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hdfs://master:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改hdfs-site.xml，如下所示：&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;Master:50090&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改 mapred-site.xml文件，这个文件需要从模板中复制一份。&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改yarn-site.xml&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;Master&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;到此，hadoop的基本配置完成。接下来需要将这个配置的hadoop文件拷贝到所有slave机器上。&lt;strong&gt;注意：slave机器上的hadoop路径要和master上的hadoop路径一直。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上诉步骤完成后就可以在master节点上启动hadoop了，使用的命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	bin/hdfs namenode -format // 这个是在hadoop第一次使用的时候执行，以后就不需要执行。
	sbin/start-dfs.sh // 启动hdfs
	sbin/start-yarn.sh // 启动yarn
	
	启动hdfs和启动yarn可以合并到一个命令：
	sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动完成后可以在master节点上使用： jps命令查看hadoop启动的进程。在slave节点上使用 jps可以查看slave节点上启动的hadoop进程。&lt;/p&gt;

&lt;p&gt;成功启动后（一般在启动的终端上没有出现warning信息一般为启动成功），可以使用http://master:50070/访问 DataNode和NameNode&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在集群上执行MapReduce例子，执行的例子可以参考伪分布式中的例子。在执行的过程中可以访问： http://master:8088/cluster来查看任务的执行情况。&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Tue, 16 Jun 2015 00:00:00 +0800</pubDate>
				<link>/2015/06/16/Hadoop%E7%9A%84%E5%8D%95%E6%9C%BA%E5%92%8C%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html</link>
				<guid isPermaLink="true">/2015/06/16/Hadoop%E7%9A%84%E5%8D%95%E6%9C%BA%E5%92%8C%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html</guid>
			</item>
		
			<item>
				<title>Java中遍历Map的各种方式</title>
				<description>&lt;p&gt;在遍历Map集合之前首先先定义一个Map对象：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Map&amp;lt;String, String&amp;gt; map = new LinkedHashMap&amp;lt;String, String&amp;gt;();
map.put(&quot;1&quot;, &quot;one&quot;);
map.put(&quot;2&quot;, &quot;two&quot;);
map.put(&quot;3&quot;, &quot;three&quot;);
map.put(&quot;4&quot;, &quot;fore&quot;);
map.put(&quot;5&quot;, &quot;five&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个地方使用的是LinkedHashMap，主要是为了确保让map中的元素是按照插入的顺序存放的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 使用keySet()方法遍历&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用keyset方法遍历，是先取出map的key组成的Set集合，通过对Set集合的遍历，然后使用map.get(key)方法取出value值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (String key : map.keySet()) {
	System.out.println(key + &quot; : &quot; + map.get(key));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2. 使用map的values()方法遍历集合的values&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;map.values()返回的是由map的值组成的Collection，这个方法只能遍历map的所有value，不能得到map的key。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (String value : map.values()) {
	System.out.println(value);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3. 使用map的entrySet()方法遍历&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用map的entrySet()方法返回一个以Entry为元素的Set集合，然后对Set集合进行遍历。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (Entry&amp;lt;String, String&amp;gt; entry : map.entrySet()) {
	System.out.println(entry.getKey() + &quot; : &quot; + 	entry.getValue());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4. 通过keySet()返回的集合的iterator遍历&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于map.keySet()返回的是一个Set集合，所以通过它的iterator()方法返回一个迭代器，通过迭代器遍历map。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator&amp;lt;String&amp;gt; it = map.keySet().iterator();
while(it1.hasNext()) {
	String key = it1.next();
	System.out.println(key + &quot; : &quot; + map.get(key));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;5. 通过values()返回的Collection的iterator遍历&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;map.values()方法返回的是一个Collection&lt;string&gt;对象，这个集合对象可以使用iterator方法访问。&lt;/string&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator&amp;lt;String&amp;gt; it = map.values().iterator();
while(it1.hasNext()) {
	String key = it1.next();
	System.out.println(key + &quot; : &quot; + map.get(key));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;6. 通过entrySet()返回的Set的iterator遍历&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;同上，map.entrySet()方法返回的是一个Set&amp;lt;Entry&amp;lt;String, String»类型的集合，可以使用iterator来访问该集合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator&amp;lt;Entry&amp;lt;String, String&amp;gt;&amp;gt; it = 	map.entrySet().iterator();
while(it3.hasNext()) {
	Entry&amp;lt;String, String&amp;gt; entry = it3.next();
	System.out.println(entry.getKey() + &quot; : &quot; + 	entry.getValue());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上总结了对map集合的集中遍历方式，根据自身需要灵活选择使用哪种方式。&lt;/p&gt;
</description>
				<pubDate>Sun, 14 Jun 2015 00:00:00 +0800</pubDate>
				<link>/2015/06/14/Java%E4%B8%ADMap%E7%9A%84%E8%AE%BF%E9%97%AE%E6%96%B9%E5%BC%8F.html</link>
				<guid isPermaLink="true">/2015/06/14/Java%E4%B8%ADMap%E7%9A%84%E8%AE%BF%E9%97%AE%E6%96%B9%E5%BC%8F.html</guid>
			</item>
		
			<item>
				<title>spring io 平台介绍</title>
				<description>&lt;p&gt;Spring IO Platform reference对Spring IO的介绍如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Spring IO Platform is primarily intended to be used with a dependency management system. It works well with both Maven and Gradle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;具体如何理解Spring IO Platform 的作用了？&lt;/p&gt;

&lt;p&gt;以前在升级Spring项目的时候是手动的一个一个升级Spring模块的版本，并且一个模块与另一个模块之间的依赖适不适合你并不知道，你还需要测试或者找资料，所以比较麻烦。Spring IO Platform它能够结合Maven (或Gradle)管理每个模块的依赖，使得开发者不再花心思研究各个Java库相互依赖的版本，只需要引入Spring IO Platform即可，因为这些库的依赖关系Spring IO Platform已经帮你验证过了。&lt;/p&gt;

&lt;p&gt;在Maven中的使用也比较简单，只需要在pom.xml文件中加入依赖管理就可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dependencyManagement&amp;gt;
	&amp;lt;dependencies&amp;gt;
		&amp;lt;dependency&amp;gt; 
			&amp;lt;groupId&amp;gt;io.spring.platform&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;platform-bom&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;1.1.2.BUILD-SNAPSHOT&amp;lt;/version&amp;gt; 
			&amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
			&amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
		&amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然也可以使用继承的方式：
	&lt;parent&gt; 
		&lt;groupid&gt;io.spring.platform&lt;/groupid&gt;
		&lt;artifactid&gt;platform-bom&lt;/artifactid&gt;
		&lt;version&gt;1.1.2.BUILD-SNAPSHOT&lt;/version&gt; 
		&lt;relativepath&gt;&lt;/relativepath&gt;
	&lt;/parent&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;http://docs.spring.io/platform/docs/1.1.2.BUILD-SNAPSHOT/reference/htmlsingle/&lt;/p&gt;

</description>
				<pubDate>Fri, 16 Jan 2015 00:00:00 +0800</pubDate>
				<link>/2015/01/16/spring_io_platform.html</link>
				<guid isPermaLink="true">/2015/01/16/spring_io_platform.html</guid>
			</item>
		
			<item>
				<title>feedback_me 插件的使用</title>
				<description>&lt;p&gt;This jQuery plug-in allows user to easily add an animatable UI widget with a feedback form which slides from the side of the screen.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;feedback_me 在使用后的效果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/5568742/5056362/a681f7e6-6cba-11e4-9eb2-bdcb2bf2d18d.png&quot; alt=&quot;1&quot; /&gt;
&lt;img src=&quot;https://cloud.githubusercontent.com/assets/5568742/5056363/c164806a-6cba-11e4-9f83-f38c9e18653a.png&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;它会附着在窗口的一边，点击后会出现信息表，填写完成后点击提交即可，提交完成后feedbach_me 会将填写的信息通过post请求发送到你指定的url地址，你可以在后台写一个controller专门负责接收这个请求。这个插件的好处在于整个过程使用简单、有效，只需要通过简单的配置就能完成。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;官方的文档的地址： http://plugins.jquery.com/feedback_me 
github的地址： https://github.com/vedmack/feedback_me&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;section&quot;&gt;看一下如何使用它：&lt;/h5&gt;

&lt;p&gt;首先他是一个jQuery 插件，需要在一开始引入jQuery，然后引入它指定的js和css文件即可。&lt;/p&gt;

&lt;p&gt;上图例子实现的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;link href=&quot;../../styles/jquery/jquery.feedback_me.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot; src=&quot;../../scripts/jquery/jquery.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot; src=&quot;../../scripts/jquery/plugin/jquery.feedback_me.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
	$(document).ready(function(){
		fm_options = {
			// 这个参数是设置这个反馈按钮在页面的哪个位置，left-bottom ...
    		position: &quot;right-top&quot;,
    		// 是否显示邮箱
    		show_email: true,
    		email_label: &quot;邮箱&quot;,
    		email_required: true,
    		// 单选框
   			show_radio_button_list: true,
   			radio_button_list_labels: [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;],
   			radio_button_list_title: &quot;给个好评哦...&quot;,
   			radio_button_list_required: false,
   			//
   			name_required: true,
    		name_label: &quot;名字&quot;,
			// 
			message_label: &quot;反馈信息&quot;,
			message_required: true,
    		show_asterisk_for_required: true,
    		// 这个很重要，这是提交后信息发送到哪里
    		feedback_url: &quot;http://.../feedback/message&quot;,
    		// 提交信息后提示
    		delayed_options: {
        		send_fail : &quot;提交失败 :(. &quot;,
       			 send_success : &quot;提交成功，谢谢参与反馈，^_^ !&quot;
    		},
    		submit_label: &quot;提交&quot;,
			// 页面按钮提示信息
			trigger_label: &quot;意见反馈&quot;
		};
		//init feedback_me plugin
		fm.init(fm_options);
	});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Mon, 05 Jan 2015 00:00:00 +0800</pubDate>
				<link>/2015/01/05/feedback_me_%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8.html</link>
				<guid isPermaLink="true">/2015/01/05/feedback_me_%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8.html</guid>
			</item>
		
			<item>
				<title>Git提交错误后如何回退</title>
				<description>&lt;blockquote&gt;
  &lt;p&gt;在使用Git的时候需要维护一个自己的分支模型，推荐使用: 
http://nvie.com/posts/a-successful-git-branching-model/  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section&quot;&gt;总体说来有一下两点：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;在中央仓库保存两个永久分支，master &amp;amp;&amp;amp; develop，master分支是发布分支，每次发布就是从master上打包发布，程序是不允许直接在master提交代码，只能通过其他分支合并到master分支。develop分支是开发分支，当develop上得源代码达到一个稳定状态的时候就可以把develop的代码合并到master上。&lt;/li&gt;
  &lt;li&gt;除去master和develop这两个永久分支，还存在一些暂时的分支。
    &lt;ul&gt;
      &lt;li&gt;线上的紧急Bug需要修复，这个时候就需要创建一个hotfix分支，这个分支是从master上检出，完成修复后双向合并到master和develop上，保证develop与master代码的同步，合并完后删除hotfix 分支。&lt;/li&gt;
      &lt;li&gt;还比如，要开发一个新功能，这个时候需要创建一个feature分支，这个分支就从develop上检出，可以把这个分支推到服务器上让更多地人参与开发，当然也可以不推倒服务器上，只在本地开发，开发完成后合并到develop上。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面这个是我们项目中的网络提交图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/5568742/5021605/91bdfa3e-6b12-11e4-8b66-3926fb2c0a29.png&quot; alt=&quot;test2&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这只是简单介说了一下分支模型，具体的介绍可以参考上面给出的链接。如果在提交的过程中直接在master上做了修改，或者不小心把master合并到了develop分支上，如何回退？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;master&quot;&gt;直接在master分支上修改代码并提交如何回退&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果直接在master分支上做了修改并提交到了服务器，这种操作在上面所描述的分支模型中是严格禁止的，如果出现这种情况如何回退：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;在本地切到master分支下，使用 git chenkout -b  temp-branch，这样就从master分支上创建了一个新的临时分支，并且切到这个分支下。&lt;/li&gt;
    &lt;li&gt;git reset –hard commitpoint, 这个commitpoint代表你要回滚的提交点&lt;/li&gt;
    &lt;li&gt;git branch -D master , 这个操作是删除本地master分支&lt;/li&gt;
    &lt;li&gt;git push origin :master, 删除远程服务器上得master分支，这里的删除就是推送一个空分支到远程master上。&lt;b&gt;但是注意的是远程master可能是一个default设置，这样服务器是不允许删除master分支，这个时候就需要在项目设置上将default标签切换到另一个分支上，上面的删除操作才能成功&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;将远程分支删掉后需要把回滚后的分支推到远程服务器上，git push origin temp-branch:master，这样就能完成回退操作&lt;/li&gt;
    &lt;li&gt;最后是删除temp-branch 分支，git checkout master, git branch -D temp-branch.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;
</description>
				<pubDate>Mon, 05 Jan 2015 00:00:00 +0800</pubDate>
				<link>/2015/01/05/Git%E6%8F%90%E4%BA%A4%E9%94%99%E8%AF%AF%E5%90%8E%E5%A6%82%E4%BD%95%E5%9B%9E%E9%80%80.html</link>
				<guid isPermaLink="true">/2015/01/05/Git%E6%8F%90%E4%BA%A4%E9%94%99%E8%AF%AF%E5%90%8E%E5%A6%82%E4%BD%95%E5%9B%9E%E9%80%80.html</guid>
			</item>
		
	</channel>
</rss>
