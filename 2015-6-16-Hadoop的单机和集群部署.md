---
layout: post
title: Hadoop的单机和集群部署

---

#### hadoop单机部署步骤：

__Required software__

* Java(Java 7 以上）
* SSH

download the latest version

__Local(Standalone) Mode__

hadoop可以直接独自运行在一个JVM程序里面。无需运行任何守护进程，所有程序都在同一个JVM上。在独立模式下测试和调试MapReduce程序很方便，因此该模式在开发阶段比较合适。在独立模式（本地模式）下将使用本地文件系统和本地MapReduce作业运行器。

__Pseudo-Distributed Mode__

可以使用伪分布式的方式运行hadoop，也就是所有的守护进程都是运行在一台机器上。

配置文件如下：


	etc/hadoop/core-site.xml:

	<configuration>
	    <property>
	        <name>fs.defaultFS</name>
	        <value>hdfs://localhost:9000</value>
	    </property>
	</configuration>

	etc/hadoop/hdfs-site.xml:

	<configuration>
	    <property>
	        <name>dfs.replication</name>
	        <value>1</value>
	    </property>
	</configuration>


现在需要使ssh localhost连接本地无需密码：

ssh localhost

如果执行这条命令需要密码，则需要执行如下命令：


	  $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
	  $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
  	

以下是一个例子，没有运行在yarn上。

* 首先需要格式化文件系统：  bin/hdfs namenode -format
* 在后台启动一个namenode 和 datanode: sbin/start-dfs.sh，启动后可以在logs目录下查看日志，也可以访问： http://localhost:50070/
* 在hdfs中创建一个目录：bin/hdfs dfs -mkdir /user
* 拷贝本地文件到hdfs中：bin/hdfs dfs -put etc/hadoop/*.xml /user
* 执行程序：bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar grep /input /output 'dfs[a-z.]+'
* 查看输出，可以先把hdfs中的文件拷贝到本地后查看：bin/hdfs dfs -get output output
* cat output/*
* 或者直接在hdfs中查看： bin/hdfs dfs -cat output/*
* 停止hdfs可以使用： sbin/stop-dfs.sh
* 可以使用jps命令查看进程。

---

* 使用： bin/hdfs dfs -rmdir /user/trssmas/output 删除指定的目录
* 使用： bin/hdfs dfs -rm /user/trssmas/output/file1 删除指定路径下的文件

__在单个节点上运行YARN__

首先需要配置：etc/hadoop/mapred-site.xml


	<configuration>
	    <property>
	        <name>mapreduce.framework.name</name>
	        <value>yarn</value>
	    </property>
	</configuration>


配置： etc/hadoop/yarn-site.xml


	<configuration>
	    <property>
	        <name>yarn.nodemanager.aux-services</name>
	        <value>mapreduce_shuffle</value>
	    </property>
	</configuration>


这个时候可以启动yarn了。


	sbin/start-yarn.sh
	sbin/stop-yarn.sh
	sbin/stop-all.sh 结束所有的进程


#### hadoop的集群部署步骤

在集群的部署和伪分布式的部署不太一样，具体操作如下：

首先本地环境是两台物理机，ip地址分别为：

* 10.249.150.51 （master)
* 10.249.150.52  (slave)

选取51作为master， 52作为slave

hadoop的版本这次选取的是： hadoop-2.5.1

__准备工作__

在安装之前需要分配一个hadoop用户专门用于hadoop的操作，同时在每台机器上安装JAVA(推荐使用oracle的JDK）和SSH。

* 修改每台主机的用户名，51这台机器为master，所以修改这台机器的用户名为master。linux下修改主机的名字会随着使用的linux发行版不同而不同，但是如果只是暂时修改主机名（就是重启后用命令修改的主机名失效）可以在所有linux发行版中使用：hostname 修改的名字。但是推荐是永久修改主机名，这里举出Ubuntu和Centos两种发行版修改主机名的方式：

	* Ubuntu：直接编辑etc下的hostname文件： vi /etc/hostname 修改主机名。编辑完后需要重启才能生效。
	* Centos：直接编辑etc/sysconfig/network：将HOSTNAME修改为主机名，如果没有就添加一行： HOSTNAME=master。编辑完后需要重新启动才能生效。

* 修改hosts文件，修改hosts文件后可以直接使用主机名代替ip地址访问其他机器。hosts文件的修改是通过编辑etc/hosts文件得到的，vi /etc/hosts文件。

		127.0.0.1 localhost
		10.249.150.51 master
		10.249.150.52 slave

	通过修改hostname 和 hosts文件，这样我们可以通过访问主机名就能访问机器了，比如可以使用：

	ping master 或者 ping slave 都能够ping通。

	**注意**：修改hostname和修改hosts文件每台机器上都要做，修改hostname是为了将每天机器的主机名改成该机器相应的名字，比如将52改成slave。修改hosts文件，每天机器都需要做相同的操作，比如：在51上要做： 10.249.150.51 master && 10.249.150.52 slave，那在52上也要做相同的操作，这样才能在每台机器上ping通所有机器。

* 配置master使用SSH无密码登录所有slave。这个操作要让master能够使用ssh无密码的访问所有slave。

	* 首先在master主机上，使用 ssh-keygen -t rsa 命令生成密钥对。
	* 然后使用 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys命令，配置ssh访问本地无需要密码。
	* 完成后可以使用： ssh master检查一下是否需要密码才能登录，如果无需密码说明ssh设置正确，否则需要重新设置一次。
	* 在完成了master的设置之后，需要把master上产生的公钥发送到每个slave机器上，命令如下： scp ~/.ssh/id_rsa.pub 用户名@slave的IP地址:~/.ssh/ 这条命令的意思是：使用scp命令将将id_rsa.pub拷贝到slave地址的~/.ssh目录下。
	* 在slave机器下执行：cat ~/.id_rsa.pub >> ~/.ssh/authorized_keys
	* 在所有的slave节点操作完成后，可以在master节点上使用ssh slave来验证是否需要密码才能登录。

__设置hadoop的配置文件__

*  需要在etc/hadoop文件中修改slaves文件，将文件中的内容全部换成所有slave的名字，注意，如果原文件中又localhost，就将localhost删掉，同时每行写一个slave机器的名字，如下所示：

		slave1
		slave2
		....
* 修改core-site.xml文件，在core-site.xml文件中配置成如下：

		<property>
			<name>fs.defaultFS</name>
			<value>hdfs://master:9000</value>
		</property>

* 修改hdfs-site.xml，如下所示：

		<property>
    		<name>dfs.namenode.secondary.http-address</name>
    		<value>Master:50090</value>
		</property>
		<property>
    		<name>dfs.replication</name>
    		<value>3</value>
		</property>

* 修改 mapred-site.xml文件，这个文件需要从模板中复制一份。

		<property>
    		<name>mapreduce.framework.name</name>
    		<value>yarn</value>
		</property>

* 修改yarn-site.xml

		<property>
    		<name>yarn.resourcemanager.hostname</name>
    		<value>Master</value>
		</property>
		<property>
    		<name>yarn.nodemanager.aux-services</name>
    		<value>mapreduce_shuffle</value>
		</property>


* 到此，hadoop的基本配置完成。接下来需要将这个配置的hadoop文件拷贝到所有slave机器上。**注意：slave机器上的hadoop路径要和master上的hadoop路径一直。**

上诉步骤完成后就可以在master节点上启动hadoop了，使用的命令如下：

		bin/hdfs namenode -format // 这个是在hadoop第一次使用的时候执行，以后就不需要执行。
		sbin/start-dfs.sh // 启动hdfs
		sbin/start-yarn.sh // 启动yarn
		
		启动hdfs和启动yarn可以合并到一个命令：
		sbin/start-all.sh
		
启动完成后可以在master节点上使用： jps命令查看hadoop启动的进程。在slave节点上使用 jps可以查看slave节点上启动的hadoop进程。

成功启动后（一般在启动的终端上没有出现warning信息一般为启动成功），可以使用http://master:50070/访问 DataNode和NameNode

* 在集群上执行MapReduce例子，执行的例子可以参考伪分布式中的例子。在执行的过程中可以访问： http://master:8088/cluster来查看任务的执行情况。
