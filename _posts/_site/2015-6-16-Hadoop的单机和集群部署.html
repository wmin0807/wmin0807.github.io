<h4 id="hadoop">hadoop单机部署步骤：</h4>

<p><strong>Required software</strong></p>

<ul>
  <li>Java(Java 7 以上）</li>
  <li>SSH</li>
</ul>

<p>download the latest version</p>

<p><strong>Local(Standalone) Mode</strong></p>

<p>hadoop可以直接独自运行在一个JVM程序里面。无需运行任何守护进程，所有程序都在同一个JVM上。在独立模式下测试和调试MapReduce程序很方便，因此该模式在开发阶段比较合适。在独立模式（本地模式）下将使用本地文件系统和本地MapReduce作业运行器。</p>

<p><strong>Pseudo-Distributed Mode</strong></p>

<p>可以使用伪分布式的方式运行hadoop，也就是所有的守护进程都是运行在一台机器上。</p>

<p>配置文件如下：</p>

<pre><code>etc/hadoop/core-site.xml:

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

etc/hadoop/hdfs-site.xml:

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>现在需要使ssh localhost连接本地无需密码：</p>

<p>ssh localhost</p>

<p>如果执行这条命令需要密码，则需要执行如下命令：</p>

<pre><code>  $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
  $ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<p>以下是一个例子，没有运行在yarn上。</p>

<ul>
  <li>首先需要格式化文件系统：  bin/hdfs namenode -format</li>
  <li>在后台启动一个namenode 和 datanode: sbin/start-dfs.sh，启动后可以在logs目录下查看日志，也可以访问： http://localhost:50070/</li>
  <li>在hdfs中创建一个目录：bin/hdfs dfs -mkdir /user</li>
  <li>拷贝本地文件到hdfs中：bin/hdfs dfs -put etc/hadoop/*.xml /user</li>
  <li>执行程序：bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar grep /input /output ‘dfs[a-z.]+’</li>
  <li>查看输出，可以先把hdfs中的文件拷贝到本地后查看：bin/hdfs dfs -get output output</li>
  <li>cat output/*</li>
  <li>或者直接在hdfs中查看： bin/hdfs dfs -cat output/*</li>
  <li>停止hdfs可以使用： sbin/stop-dfs.sh</li>
  <li>可以使用jps命令查看进程。</li>
</ul>

<hr />

<ul>
  <li>使用： bin/hdfs dfs -rmdir /user/trssmas/output 删除指定的目录</li>
  <li>使用： bin/hdfs dfs -rm /user/trssmas/output/file1 删除指定路径下的文件</li>
</ul>

<p><strong>在单个节点上运行YARN</strong></p>

<p>首先需要配置：etc/hadoop/mapred-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置： etc/hadoop/yarn-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>这个时候可以启动yarn了。</p>

<pre><code>sbin/start-yarn.sh
sbin/stop-yarn.sh
sbin/stop-all.sh 结束所有的进程
</code></pre>

<h4 id="hadoop-1">hadoop的集群部署步骤</h4>

<p>在集群的部署和伪分布式的部署不太一样，具体操作如下：</p>

<p>首先本地环境是两台物理机，ip地址分别为：</p>

<ul>
  <li>10.249.150.51 （master)</li>
  <li>10.249.150.52  (slave)</li>
</ul>

<p>选取51作为master， 52作为slave</p>

<p>hadoop的版本这次选取的是： hadoop-2.5.1</p>

<p><strong>准备工作</strong></p>

<p>在安装之前需要分配一个hadoop用户专门用于hadoop的操作，同时在每台机器上安装JAVA(推荐使用oracle的JDK）和SSH。</p>

<ul>
  <li>
    <p>修改每台主机的用户名，51这台机器为master，所以修改这台机器的用户名为master。linux下修改主机的名字会随着使用的linux发行版不同而不同，但是如果只是暂时修改主机名（就是重启后用命令修改的主机名失效）可以在所有linux发行版中使用：hostname 修改的名字。但是推荐是永久修改主机名，这里举出Ubuntu和Centos两种发行版修改主机名的方式：</p>

    <ul>
      <li>Ubuntu：直接编辑etc下的hostname文件： vi /etc/hostname 修改主机名。编辑完后需要重启才能生效。</li>
      <li>Centos：直接编辑etc/sysconfig/network：将HOSTNAME修改为主机名，如果没有就添加一行： HOSTNAME=master。编辑完后需要重新启动才能生效。</li>
    </ul>
  </li>
  <li>
    <p>修改hosts文件，修改hosts文件后可以直接使用主机名代替ip地址访问其他机器。hosts文件的修改是通过编辑etc/hosts文件得到的，vi /etc/hosts文件。</p>

    <pre><code>  127.0.0.1 localhost
  10.249.150.51 master
  10.249.150.52 slave
</code></pre>

    <p>通过修改hostname 和 hosts文件，这样我们可以通过访问主机名就能访问机器了，比如可以使用：</p>

    <p>ping master 或者 ping slave 都能够ping通。</p>

    <p><strong>注意</strong>：修改hostname和修改hosts文件每台机器上都要做，修改hostname是为了将每天机器的主机名改成该机器相应的名字，比如将52改成slave。修改hosts文件，每天机器都需要做相同的操作，比如：在51上要做： 10.249.150.51 master &amp;&amp; 10.249.150.52 slave，那在52上也要做相同的操作，这样才能在每台机器上ping通所有机器。</p>
  </li>
  <li>
    <p>配置master使用SSH无密码登录所有slave。这个操作要让master能够使用ssh无密码的访问所有slave。</p>

    <ul>
      <li>首先在master主机上，使用 ssh-keygen -t rsa 命令生成密钥对。</li>
      <li>然后使用 cat ~/.ssh/id_rsa.pub » ~/.ssh/authorized_keys命令，配置ssh访问本地无需要密码。</li>
      <li>完成后可以使用： ssh master检查一下是否需要密码才能登录，如果无需密码说明ssh设置正确，否则需要重新设置一次。</li>
      <li>在完成了master的设置之后，需要把master上产生的公钥发送到每个slave机器上，命令如下： scp ~/.ssh/id_rsa.pub 用户名@slave的IP地址:~/.ssh/ 这条命令的意思是：使用scp命令将将id_rsa.pub拷贝到slave地址的~/.ssh目录下。</li>
      <li>在slave机器下执行：cat ~/.id_rsa.pub » ~/.ssh/authorized_keys</li>
      <li>在所有的slave节点操作完成后，可以在master节点上使用ssh slave来验证是否需要密码才能登录。</li>
    </ul>
  </li>
</ul>

<p><strong>设置hadoop的配置文件</strong></p>

<ul>
  <li>
    <p>需要在etc/hadoop文件中修改slaves文件，将文件中的内容全部换成所有slave的名字，注意，如果原文件中又localhost，就将localhost删掉，同时每行写一个slave机器的名字，如下所示：</p>

    <pre><code> slave1
 slave2
 ....
</code></pre>
  </li>
  <li>
    <p>修改core-site.xml文件，在core-site.xml文件中配置成如下：</p>

    <pre><code>  &lt;property&gt;
      &lt;name&gt;fs.defaultFS&lt;/name&gt;
      &lt;value&gt;hdfs://master:9000&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
  </li>
  <li>
    <p>修改hdfs-site.xml，如下所示：</p>

    <pre><code>  &lt;property&gt;
  		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
  		&lt;value&gt;Master:50090&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
  		&lt;name&gt;dfs.replication&lt;/name&gt;
  		&lt;value&gt;3&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
  </li>
  <li>
    <p>修改 mapred-site.xml文件，这个文件需要从模板中复制一份。</p>

    <pre><code>  &lt;property&gt;
  		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
  		&lt;value&gt;yarn&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
  </li>
  <li>
    <p>修改yarn-site.xml</p>

    <pre><code>  &lt;property&gt;
  		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
  		&lt;value&gt;Master&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
  		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
  		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
  </li>
  <li>
    <p>到此，hadoop的基本配置完成。接下来需要将这个配置的hadoop文件拷贝到所有slave机器上。<strong>注意：slave机器上的hadoop路径要和master上的hadoop路径一直。</strong></p>
  </li>
</ul>

<p>上诉步骤完成后就可以在master节点上启动hadoop了，使用的命令如下：</p>

<pre><code>	bin/hdfs namenode -format // 这个是在hadoop第一次使用的时候执行，以后就不需要执行。
	sbin/start-dfs.sh // 启动hdfs
	sbin/start-yarn.sh // 启动yarn
	
	启动hdfs和启动yarn可以合并到一个命令：
	sbin/start-all.sh
</code></pre>

<p>启动完成后可以在master节点上使用： jps命令查看hadoop启动的进程。在slave节点上使用 jps可以查看slave节点上启动的hadoop进程。</p>

<p>成功启动后（一般在启动的终端上没有出现warning信息一般为启动成功），可以使用http://master:50070/访问 DataNode和NameNode</p>

<ul>
  <li>在集群上执行MapReduce例子，执行的例子可以参考伪分布式中的例子。在执行的过程中可以访问： http://master:8088/cluster来查看任务的执行情况。</li>
</ul>
